# ğŸ¤ Whisper Model Size Guide

## Quick Comparison

| Model | Speed | Accuracy | VRAM | Use Case |
|-------|-------|----------|------|----------|
| **tiny** | âš¡âš¡âš¡ | ğŸŸ¡ Basic | 1GB | Quick tests, simple audio |
| **base** | âš¡âš¡ | ğŸŸ¢ Good | 1GB | **DEFAULT - balanced** |
| **small** | âš¡ | ğŸŸ¢ Better | 2GB | Meetings, podcasts |
| **medium** | ğŸ¢ | ğŸ”µ Great | 5GB | Interviews, important calls |
| **large** | ğŸŒ | ğŸ† Best | 10GB | Critical transcription |

## When to Use Each

### ğŸŸ¡ Tiny
**Use for:** Quick tests, simple audio, single speaker
- âš¡ **Speed:** 10x faster than large
- ğŸ¯ **Accuracy:** 70-80% (good enough for many use cases)
- ğŸ’¾ **RAM:** Only 1GB needed
- ğŸ’° **Cost:** Cheapest

**Example:** Testing the system, short voice notes

---

### ğŸŸ¢ Base (DEFAULT)
**Use for:** Daily transcription, multi-speaker, accents
- âš¡ **Speed:** 4x faster than large
- ğŸ¯ **Accuracy:** 85-90% (great for most use cases)
- ğŸ’¾ **RAM:** 1GB needed
- ğŸ’° **Cost:** Good balance

**Example:** Meeting transcription, phone calls

---

### ğŸŸ¢ Small
**Use for:** Professional use, technical terms, multiple accents
- âš¡ **Speed:** 2x faster than large
- ğŸ¯ **Accuracy:** 90-93% (professional grade)
- ğŸ’¾ **RAM:** 2GB needed
- ğŸ’° **Cost:** Moderate

**Example:** Podcasts, interviews, business calls

---

### ğŸ”µ Medium
**Use for:** Important calls, legal/medical, critical accuracy
- âš¡ **Speed:** Slower but acceptable
- ğŸ¯ **Accuracy:** 93-95% (near-human)
- ğŸ’¾ **RAM:** 5GB needed
- ğŸ’° **Cost:** Higher

**Example:** Court transcription, medical notes

---

### ğŸ† Large
**Use for:** Maximum accuracy needed, research, archiving
- âš¡ **Speed:** Slowest (but worth it)
- ğŸ¯ **Accuracy:** 95-98% (human-level)
- ğŸ’¾ **RAM:** 10GB needed
- ğŸ’° **Cost:** Most expensive

**Example:** Critical interviews, archival, research

## Speed Comparison

**For a 5-minute audio file:**

| Model | GPU Time | Relative |
|-------|----------|----------|
| tiny | 5 sec | 10x |
| base | 12 sec | 4x |
| small | 25 sec | 2x |
| medium | 50 sec | 1x |
| large | 100 sec | 0.5x |

## Cost on Modal (T4 GPU)

| Model | Per Hour | Per 5-Min File |
|-------|----------|----------------|
| tiny | ~$0.15 | ~$0.001 |
| base | ~$0.15 | ~$0.003 |
| small | ~$0.15 | ~$0.006 |
| medium | ~$0.30 | ~$0.025 |
| large | ~$0.60 | ~$0.10 |

## Recommendations

### **Default: Base** âœ…
- Best balance of speed/accuracy
- 1GB VRAM (runs on any GPU)
- Good enough for 90% of use cases

### **Speed Priority: Tiny** âš¡
- When you need instant results
- Acceptable quality for drafts
- Great for testing

### **Quality Priority: Large** ğŸ†
- When accuracy is critical
- Worth the wait for important content
- Near-perfect transcription

## API Usage

```bash
# Tiny - fastest
curl -X POST https://api.modal.run/transcribe \
  -F "file=@audio.ogg" \
  -F "model=tiny"

# Base - balanced (DEFAULT)
curl -X POST https://api.modal.run/transcribe \
  -F "file=@audio.ogg" \
  -F "model=base"

# Large - best quality
curl -X POST https://api.modal.run/transcribe \
  -F "file=@audio.ogg" \
  -F "model=large"
```

## Volume Storage

Pre-download all models to Modal Volume:
```bash
modal run ramble_mode_v2_multi.py::download_models
```

This caches models so:
- âœ… No download wait on cold start
- âœ… Instant model switching
- âœ… Faster deployments
- âœ… All 5 models ready

**Storage cost:** ~15GB total (~$0.50/month)
